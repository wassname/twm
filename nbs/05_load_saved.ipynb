{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch with loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from twm.replay_buffer import ReplayBuffer\n",
    "from twm.config import CONFIGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('../wandb/run-20240601_210820-jnc0zpm3/files/agent_0.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/agent_30000.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/agent_50000.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/agent_40000.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/agent_20000.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/agent_final.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/agent_10000.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/agent_0.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/files/agent_30000.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/files/agent_50000.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/files/agent_40000.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/files/agent_20000.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/files/agent_final.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/files/agent_10000.pt'), PosixPath('../wandb/run-20240601_075812-0l0foh9u/files/files/agent_0.pt'), PosixPath('../wandb/run-20240602_215922-mv00l07m/files/agent_700000.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_400000.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_300000.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_600000.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_800000.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_900000.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_700000.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_500000.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_final.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_100000.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_0.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/agent_200000.pt'), PosixPath('../wandb/run-20240601_211958-mv00l07m/files/files/agent_final.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_400000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_300000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_600000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_800000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_900000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_700000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_500000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_final.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_100000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_0.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/agent_200000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_400000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_300000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_600000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_800000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_900000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_700000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_500000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_final.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_100000.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_0.pt'), PosixPath('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_200000.pt'), PosixPath('../wandb/run-20240601_204428-qql43soz/files/agent_0.pt'), PosixPath('../wandb/run-20240601_204428-qql43soz/files/files/agent_0.pt')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('../wandb/run-20240601_204428-qql43soz/files/files/agent_0.pt')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the latest save\n",
    "saves = list(Path('../wandb/').glob('**/agent_*.pt'))\n",
    "# saves = sorted(saves, key=lambda x: x.stat().st_mtime)\n",
    "\n",
    "print(saves)\n",
    "save = saves[-1]\n",
    "\n",
    "# save = Path('../wandb/run-20240601_113918-ctz0yebk/files/files/agent_final.pt')\n",
    "save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>date</th>\n",
       "      <th>date2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../wandb/run-20240601_210820-jnc0zpm3/files/ag...</td>\n",
       "      <td>1.717247e+09</td>\n",
       "      <td>20240601_210820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/ag...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/ag...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/ag...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/ag...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/ag...</td>\n",
       "      <td>1.717201e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/ag...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/ag...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/fi...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/fi...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/fi...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/fi...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/fi...</td>\n",
       "      <td>1.717201e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/fi...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>../wandb/run-20240601_075812-0l0foh9u/files/fi...</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>20240601_075812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717253e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717252e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717255e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717258e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717259e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717257e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717254e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717260e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717249e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717248e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/ag...</td>\n",
       "      <td>1.717251e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>../wandb/run-20240601_211958-mv00l07m/files/fi...</td>\n",
       "      <td>1.717260e+09</td>\n",
       "      <td>20240601_211958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717218e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717217e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717220e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717221e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717222e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717220e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717219e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717223e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717215e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717214e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/ag...</td>\n",
       "      <td>1.717216e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717218e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717217e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717220e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717221e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717222e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717220e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717219e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717223e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717215e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717214e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>../wandb/run-20240601_113918-ctz0yebk/files/fi...</td>\n",
       "      <td>1.717216e+09</td>\n",
       "      <td>20240601_113918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>../wandb/run-20240601_204428-qql43soz/files/ag...</td>\n",
       "      <td>1.717246e+09</td>\n",
       "      <td>20240601_204428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>../wandb/run-20240601_204428-qql43soz/files/fi...</td>\n",
       "      <td>1.717246e+09</td>\n",
       "      <td>20240601_204428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    f          date  \\\n",
       "0   ../wandb/run-20240601_210820-jnc0zpm3/files/ag...  1.717247e+09   \n",
       "1   ../wandb/run-20240601_075812-0l0foh9u/files/ag...  1.717200e+09   \n",
       "2   ../wandb/run-20240601_075812-0l0foh9u/files/ag...  1.717200e+09   \n",
       "3   ../wandb/run-20240601_075812-0l0foh9u/files/ag...  1.717200e+09   \n",
       "4   ../wandb/run-20240601_075812-0l0foh9u/files/ag...  1.717200e+09   \n",
       "5   ../wandb/run-20240601_075812-0l0foh9u/files/ag...  1.717201e+09   \n",
       "6   ../wandb/run-20240601_075812-0l0foh9u/files/ag...  1.717200e+09   \n",
       "7   ../wandb/run-20240601_075812-0l0foh9u/files/ag...  1.717200e+09   \n",
       "8   ../wandb/run-20240601_075812-0l0foh9u/files/fi...  1.717200e+09   \n",
       "9   ../wandb/run-20240601_075812-0l0foh9u/files/fi...  1.717200e+09   \n",
       "10  ../wandb/run-20240601_075812-0l0foh9u/files/fi...  1.717200e+09   \n",
       "11  ../wandb/run-20240601_075812-0l0foh9u/files/fi...  1.717200e+09   \n",
       "12  ../wandb/run-20240601_075812-0l0foh9u/files/fi...  1.717201e+09   \n",
       "13  ../wandb/run-20240601_075812-0l0foh9u/files/fi...  1.717200e+09   \n",
       "14  ../wandb/run-20240601_075812-0l0foh9u/files/fi...  1.717200e+09   \n",
       "15  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717253e+09   \n",
       "16  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717252e+09   \n",
       "17  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717255e+09   \n",
       "18  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717258e+09   \n",
       "19  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717259e+09   \n",
       "20  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717257e+09   \n",
       "21  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717254e+09   \n",
       "22  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717260e+09   \n",
       "23  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717249e+09   \n",
       "24  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717248e+09   \n",
       "25  ../wandb/run-20240601_211958-mv00l07m/files/ag...  1.717251e+09   \n",
       "26  ../wandb/run-20240601_211958-mv00l07m/files/fi...  1.717260e+09   \n",
       "27  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717218e+09   \n",
       "28  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717217e+09   \n",
       "29  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717220e+09   \n",
       "30  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717221e+09   \n",
       "31  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717222e+09   \n",
       "32  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717220e+09   \n",
       "33  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717219e+09   \n",
       "34  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717223e+09   \n",
       "35  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717215e+09   \n",
       "36  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717214e+09   \n",
       "37  ../wandb/run-20240601_113918-ctz0yebk/files/ag...  1.717216e+09   \n",
       "38  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717218e+09   \n",
       "39  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717217e+09   \n",
       "40  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717220e+09   \n",
       "41  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717221e+09   \n",
       "42  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717222e+09   \n",
       "43  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717220e+09   \n",
       "44  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717219e+09   \n",
       "45  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717223e+09   \n",
       "46  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717215e+09   \n",
       "47  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717214e+09   \n",
       "48  ../wandb/run-20240601_113918-ctz0yebk/files/fi...  1.717216e+09   \n",
       "49  ../wandb/run-20240601_204428-qql43soz/files/ag...  1.717246e+09   \n",
       "50  ../wandb/run-20240601_204428-qql43soz/files/fi...  1.717246e+09   \n",
       "\n",
       "              date2  \n",
       "0   20240601_210820  \n",
       "1   20240601_075812  \n",
       "2   20240601_075812  \n",
       "3   20240601_075812  \n",
       "4   20240601_075812  \n",
       "5   20240601_075812  \n",
       "6   20240601_075812  \n",
       "7   20240601_075812  \n",
       "8   20240601_075812  \n",
       "9   20240601_075812  \n",
       "10  20240601_075812  \n",
       "11  20240601_075812  \n",
       "12  20240601_075812  \n",
       "13  20240601_075812  \n",
       "14  20240601_075812  \n",
       "15  20240601_211958  \n",
       "16  20240601_211958  \n",
       "17  20240601_211958  \n",
       "18  20240601_211958  \n",
       "19  20240601_211958  \n",
       "20  20240601_211958  \n",
       "21  20240601_211958  \n",
       "22  20240601_211958  \n",
       "23  20240601_211958  \n",
       "24  20240601_211958  \n",
       "25  20240601_211958  \n",
       "26  20240601_211958  \n",
       "27  20240601_113918  \n",
       "28  20240601_113918  \n",
       "29  20240601_113918  \n",
       "30  20240601_113918  \n",
       "31  20240601_113918  \n",
       "32  20240601_113918  \n",
       "33  20240601_113918  \n",
       "34  20240601_113918  \n",
       "35  20240601_113918  \n",
       "36  20240601_113918  \n",
       "37  20240601_113918  \n",
       "38  20240601_113918  \n",
       "39  20240601_113918  \n",
       "40  20240601_113918  \n",
       "41  20240601_113918  \n",
       "42  20240601_113918  \n",
       "43  20240601_113918  \n",
       "44  20240601_113918  \n",
       "45  20240601_113918  \n",
       "46  20240601_113918  \n",
       "47  20240601_113918  \n",
       "48  20240601_113918  \n",
       "49  20240601_204428  \n",
       "50  20240601_204428  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = [dict(f=f, date=f.stat().st_mtime, date2=str(f.parent).split('/')[2].split('-')[1]) for f in saves]\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['config', 'state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'buffer_capacity': 200000,\n",
       " 'buffer_temperature': 20.0,\n",
       " 'buffer_prefill': 20000,\n",
       " 'train_it_budget': 3000000,\n",
       " 'pretrain_it_budget': 20000000,\n",
       " 'pretrain_obs_p': 0.4,\n",
       " 'pretrain_dyn_p': 0.6,\n",
       " 'save_every': 100000,\n",
       " 'eval_every': 25000,\n",
       " 'eval_episodes': 10,\n",
       " 'final_eval_episodes': 100,\n",
       " 'env_step_budget': 1000000,\n",
       " 'env_frame_size': 8268,\n",
       " 'env_frame_stack': 2,\n",
       " 'env_time_limit': 10000,\n",
       " 'env_discount_factor': 0.99,\n",
       " 'env_discount_lambda': 0.95,\n",
       " 'wm_batch_size': 800,\n",
       " 'wm_sequence_length': 16,\n",
       " 'wm_train_steps': 1,\n",
       " 'wm_memory_length': 16,\n",
       " 'wm_discount_threshold': 0.1,\n",
       " 'z_categoricals': 64,\n",
       " 'z_categories': 64,\n",
       " 'obs_act': 'silu',\n",
       " 'obs_norm': 'none',\n",
       " 'obs_dropout': 0,\n",
       " 'obs_lr': 0.0001,\n",
       " 'obs_wd': 1e-06,\n",
       " 'obs_eps': 1e-05,\n",
       " 'obs_grad_clip': 100,\n",
       " 'obs_entropy_coef': 5,\n",
       " 'obs_entropy_threshold': 0.1,\n",
       " 'obs_consistency_coef': 0.01,\n",
       " 'obs_decoder_coef': 1,\n",
       " 'dyn_embed_dim': 256,\n",
       " 'dyn_num_heads': 4,\n",
       " 'dyn_num_layers': 10,\n",
       " 'dyn_feedforward_dim': 1024,\n",
       " 'dyn_head_dim': 64,\n",
       " 'dyn_z_dims': [512, 512, 512, 512],\n",
       " 'dyn_reward_dims': [256, 256, 256, 256],\n",
       " 'dyn_discount_dims': [256, 256, 256, 256],\n",
       " 'dyn_input_rewards': True,\n",
       " 'dyn_input_discounts': False,\n",
       " 'dyn_act': 'silu',\n",
       " 'dyn_norm': 'none',\n",
       " 'dyn_dropout': 0.1,\n",
       " 'dyn_lr': 0.0001,\n",
       " 'dyn_wd': 1e-06,\n",
       " 'dyn_eps': 1e-05,\n",
       " 'dyn_grad_clip': 100,\n",
       " 'dyn_z_coef': 1,\n",
       " 'dyn_reward_coef': 10,\n",
       " 'dyn_discount_coef': 50,\n",
       " 'ac_batch_size': 800,\n",
       " 'ac_horizon': 15,\n",
       " 'ac_act': 'silu',\n",
       " 'ac_norm': 'none',\n",
       " 'ac_dropout': 0,\n",
       " 'ac_input_h': False,\n",
       " 'ac_h_norm': 'none',\n",
       " 'ac_normalize_advantages': False,\n",
       " 'actor_dims': [512, 512, 512, 512],\n",
       " 'actor_lr': 0.0001,\n",
       " 'actor_eps': 1e-05,\n",
       " 'actor_wd': 1e-06,\n",
       " 'actor_entropy_coef': 0.01,\n",
       " 'actor_entropy_threshold': 0.1,\n",
       " 'actor_grad_clip': 1,\n",
       " 'critic_dims': [512, 512, 512, 512],\n",
       " 'critic_lr': 1e-05,\n",
       " 'critic_eps': 1e-05,\n",
       " 'critic_wd': 1e-06,\n",
       " 'critic_grad_clip': 1,\n",
       " 'critic_target_interval': 1,\n",
       " 'game': 'Craftax-Symbolic-v1',\n",
       " 'seed': 42,\n",
       " 'model_device': 'cpu',\n",
       " 'buffer_device': 'cpu',\n",
       " 'cpu_p': 0.5,\n",
       " 'save': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load(save)\n",
    "print(state.keys())\n",
    "config = state['config']\n",
    "config['model_device'] = 'cpu'\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading textures from cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Agent(\n",
       "  (wm): WorldModel(\n",
       "    (obs_model): ObservationModel(\n",
       "      (encoder): Sequential(\n",
       "        (0): Flatten(start_dim=1, end_dim=-1)\n",
       "        (1): MLP(\n",
       "          (act): SiLU()\n",
       "          (linear1): Linear(in_features=16536, out_features=512, bias=True)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear3): Linear(in_features=512, out_features=4096, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (decoder): Sequential(\n",
       "        (0): MLP(\n",
       "          (act): SiLU()\n",
       "          (linear1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear3): Linear(in_features=512, out_features=16536, bias=True)\n",
       "        )\n",
       "        (1): Unflatten(dim=1, unflattened_size=(2, 8268))\n",
       "      )\n",
       "    )\n",
       "    (dyn_model): DynamicsModel(\n",
       "      (prediction_net): PredictionNet(\n",
       "        (embeds): ModuleDict(\n",
       "          (z): MLP(\n",
       "            (act): SiLU()\n",
       "            (linear1): Linear(in_features=4096, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (a): Embedding(43, 256)\n",
       "          (r): MLP(\n",
       "            (act): SiLU()\n",
       "            (linear1): Linear(in_features=1, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (transformer): TransformerXLDecoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-9): 10 x TransformerXLDecoderLayer(\n",
       "              (self_attn): RelativeMultiheadSelfAttention(\n",
       "                (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "                (pos_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (act): SiLU()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (pos_enc): PositionalEncoding(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (out_heads): ModuleDict(\n",
       "          (z): MLP(\n",
       "            (act): SiLU()\n",
       "            (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (linear3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (linear4): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (linear5): Linear(in_features=512, out_features=4096, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (r): MLP(\n",
       "            (act): SiLU()\n",
       "            (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (linear3): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (linear4): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (linear5): Linear(in_features=256, out_features=1, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (g): MLP(\n",
       "            (act): SiLU()\n",
       "            (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (linear3): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (linear4): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (linear5): Linear(in_features=256, out_features=1, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ac): ActorCritic(\n",
       "    (h_norm): Identity()\n",
       "    (trunk): Identity()\n",
       "    (actor_model): MLP(\n",
       "      (act): SiLU()\n",
       "      (linear1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear4): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear5): Linear(in_features=512, out_features=43, bias=True)\n",
       "    )\n",
       "    (critic_model): MLP(\n",
       "      (act): SiLU()\n",
       "      (linear1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear4): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear5): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from twm.trainer import Trainer\n",
    "trainer = Trainer(config)\n",
    "trainer.agent.load_state_dict(state['state_dict'])\n",
    "trainer.agent.eval()\n",
    "agent = trainer.agent\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = trainer._create_env_from_config(config)\n",
    "o,_  = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(616)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's pretty sparse\n",
    "(o>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8268])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " None,\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " tensor([], size=(1, 0)),\n",
       " tensor([], size=(1, 0), dtype=torch.bool))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from twm.agent import Agent, Dreamer\n",
    "dreamer = Dreamer(\n",
    "    config, agent.wm, mode=\"observe\", ac=agent.ac, store_data=False\n",
    ")\n",
    "dreamer.observe_reset_single(o[None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dreamer.act(epsilon=0)\n",
    "o, r, terminated, truncated, info = env.step(a.item())\n",
    "\n",
    "device = next(iter(agent.wm.parameters())).device\n",
    "o = o.unsqueeze(0).unsqueeze(1).to(device).float()\n",
    "r = torch.as_tensor([[r]], dtype=torch.float, device=device)\n",
    "terminated = torch.as_tensor([[terminated]], device=device)\n",
    "truncated = torch.as_tensor([[terminated]], device=device)\n",
    "\n",
    "z_dream, h_dream, g_dream, d_dream, weights_dream = dreamer.observe_step(a, o, r, terminated, truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=110x130>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = agent.wm.obs_model.decode(dreamer.prev_z)\n",
    "from PIL import ImageDraw\n",
    "from twm import utils\n",
    "from einops import rearrange\n",
    "from twm.envs.craftax import craftax_symobs_to_img\n",
    "img = craftax_symobs_to_img(o.detach(), env.unwrapped.env_state).squeeze(2)[0][0][-1]\n",
    "img = rearrange(img, 'h w c -> c h w') / 255.0\n",
    "recon_img = utils.to_image(img)\n",
    "recon_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m g \u001b[38;5;241m=\u001b[39m wm\u001b[38;5;241m.\u001b[39mto_discounts(terminated)\n\u001b[1;32m     24\u001b[0m tgt_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# z.shape[1]\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m preds, h, mems \u001b[38;5;241m=\u001b[39m \u001b[43mdyn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_consistency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/twm/world_model.py:450\u001b[0m, in \u001b[0;36mDynamicsModel.predict\u001b[0;34m(self, z, a, r, g, d, tgt_length, heads, mems, return_attention, compute_consistency)\u001b[0m\n\u001b[1;32m    447\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m: z, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m: a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m: r, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m\"\u001b[39m: g}\n\u001b[1;32m    448\u001b[0m heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(heads) \u001b[38;5;28;01mif\u001b[39;00m heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 450\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_net\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmems\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m out, h, mems, attention \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m return_attention \u001b[38;5;28;01melse\u001b[39;00m (outputs \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m,))\n\u001b[1;32m    460\u001b[0m preds \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/twm/nets.py:922\u001b[0m, in \u001b[0;36mPredictionNet.forward\u001b[0;34m(self, inputs, tgt_length, stop_mask, heads, mems, return_attention)\u001b[0m\n\u001b[1;32m    919\u001b[0m hiddens, mems, attention \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m return_attention \u001b[38;5;28;01melse\u001b[39;00m (outputs \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m,))\n\u001b[1;32m    921\u001b[0m \u001b[38;5;66;03m# take outputs at last current\u001b[39;00m\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m hiddens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tgt_length\n\u001b[1;32m    923\u001b[0m out_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m    924\u001b[0m     tgt_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mnum_modalities, device\u001b[38;5;241m=\u001b[39minputs\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    925\u001b[0m )\u001b[38;5;241m.\u001b[39mflip([\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    926\u001b[0m hiddens \u001b[38;5;241m=\u001b[39m hiddens[:, out_idx]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wm = trainer.agent.wm\n",
    "obs_model = wm.obs_model\n",
    "dyn_model = wm.dyn_model\n",
    "\n",
    "o = o.detach()\n",
    "\n",
    "wm.eval()\n",
    "with torch.no_grad():\n",
    "    context_z_dist = obs_model.encode(o[:, :1])\n",
    "    context_z = obs_model.sample_z(context_z_dist)\n",
    "    next_z_dist = obs_model.encode(o[:, -1:])\n",
    "    next_logits = next_z_dist.base_dist.logits\n",
    "    \n",
    "z_dist = obs_model.encode(o)\n",
    "z = obs_model.sample_z(z_dist, reparameterized=True)\n",
    "recons = obs_model.decode(z)\n",
    "\n",
    "# dynamics model\n",
    "z = z.detach()\n",
    "z = torch.cat([context_z, z], dim=1)\n",
    "d = torch.logical_or(terminated, truncated)\n",
    "g = wm.to_discounts(terminated)\n",
    "\n",
    "tgt_length = 1 # z.shape[1]\n",
    "\n",
    "preds, h, mems = dyn_model.predict(\n",
    "    z[:, 1:], a, r[:, :-1], g[:, :-1], d[:, :-1], tgt_length, compute_consistency=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_logits = z_dist.base_dist.logits\n",
    "target_logits = torch.cat(\n",
    "    [z_logits[:, 1:].detach(), next_logits.detach()], dim=1\n",
    ")\n",
    "target_logits.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [2, 2, 8268]              --\n",
       "├─MLP: 1-1                               [2, 16536]                --\n",
       "│    └─Linear: 2-1                       [2, 512]                  2,097,664\n",
       "│    └─SiLU: 2-2                         [2, 512]                  --\n",
       "│    └─Linear: 2-3                       [2, 512]                  262,656\n",
       "│    └─SiLU: 2-4                         [2, 512]                  --\n",
       "│    └─Linear: 2-5                       [2, 16536]                8,482,968\n",
       "├─Unflatten: 1-2                         [2, 2, 8268]              --\n",
       "==========================================================================================\n",
       "Total params: 10,843,288\n",
       "Trainable params: 10,843,288\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 21.69\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 0.28\n",
       "Params size (MB): 43.37\n",
       "Estimated Total Size (MB): 43.69\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "agent.wm\n",
    "agent.ac\n",
    "\n",
    "batch_size = 16\n",
    "summary(obs_model.encoder, input_data=o)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [2, 2, 8268]              --\n",
       "├─MLP: 1-1                               [2, 16536]                --\n",
       "│    └─Linear: 2-1                       [2, 512]                  2,097,664\n",
       "│    └─SiLU: 2-2                         [2, 512]                  --\n",
       "│    └─Linear: 2-3                       [2, 512]                  262,656\n",
       "│    └─SiLU: 2-4                         [2, 512]                  --\n",
       "│    └─Linear: 2-5                       [2, 16536]                8,482,968\n",
       "├─Unflatten: 1-2                         [2, 2, 8268]              --\n",
       "==========================================================================================\n",
       "Total params: 10,843,288\n",
       "Trainable params: 10,843,288\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 21.69\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 0.28\n",
       "Params size (MB): 43.37\n",
       "Estimated Total Size (MB): 43.69\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(obs_model.decoder, input_data=z.flatten(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 4096]),\n",
       " torch.Size([1, 1]),\n",
       " torch.Size([1, 1]),\n",
       " torch.Size([1, 1]),\n",
       " torch.Size([1, 1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape, a.shape, g.shape, r.shape, d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [MLP: 2, Linear: 3, SiLU: 3, Embedding: 2, MLP: 2, Linear: 3, SiLU: 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/.venv/lib/python3.11/site-packages/torchinfo/torchinfo.py:297\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 297\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# Should not reach this point, since process_input_data ensures\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# x is either a list, tuple, or dict\u001b[39;00m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/twm/nets.py:893\u001b[0m, in \u001b[0;36mPredictionNet.forward\u001b[0;34m(self, inputs, tgt_length, stop_mask, heads, mems, return_attention)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m src_length\n\u001b[0;32m--> 893\u001b[0m     src_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/twm/nets.py:805\u001b[0m, in \u001b[0;36mPredictionNet._get_mask\u001b[0;34m(self, src_length, tgt_length, device, stop_mask)\u001b[0m\n\u001b[1;32m    804\u001b[0m num_modalities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodality_order)\n\u001b[0;32m--> 805\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m stop_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m num_modalities \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_current \u001b[38;5;241m==\u001b[39m src_length\n\u001b[1;32m    807\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_base_mask(src_length, tgt_length, device)\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# {\"z\": z, \"a\": a, \"r\": r[:, :-1], \"g\": g[:, :-1]}\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# tgt_length = 1 # z.shape[1]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     z[:, 1:], a, r[:, :-1], g[:, :-1], d[:, :-1], tgt_length, compute_consistency=True\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     10\u001b[0m tgt_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdyn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_length\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/.venv/lib/python3.11/site-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/worldmodels/twm_llm/.venv/lib/python3.11/site-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [MLP: 2, Linear: 3, SiLU: 3, Embedding: 2, MLP: 2, Linear: 3, SiLU: 3]"
     ]
    }
   ],
   "source": [
    "# {\"z\": z, \"a\": a, \"r\": r[:, :-1], \"g\": g[:, :-1]}\n",
    "\n",
    "# tgt_length = 1 # z.shape[1]\n",
    "\n",
    "# preds, h, mems = dyn_model.predict(\n",
    "#     z[:, 1:], a, r[:, :-1], g[:, :-1], d[:, :-1], tgt_length, compute_consistency=True\n",
    "# )\n",
    "\n",
    "\n",
    "tgt_length = 1\n",
    "summary(dyn_model.prediction_net, input_data=dict(inputs={\"z\": z[:, 1:], \"a\": a, \"r\": r[:, :-1], \"g\": g[:, :-1]}), tgt_length=tgt_length+1, stop_mask=d, heads=(\"z\", \"r\", \"g\"), mems=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorial?\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "z_categoricals = 512\n",
    "z_categories = 32\n",
    "z_logits = torch.randn(1, 1,  z_categoricals, z_categories)\n",
    "temperature = 1\n",
    "z_dist = D.Independent(\n",
    "            D.OneHotCategoricalStraightThrough(logits=z_logits / temperature), 1\n",
    "        )\n",
    "z_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dist.rsample().argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dist = ObservationModel.create_z_dist(z_logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
